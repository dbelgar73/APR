{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variaciones sobre el modelo inicial \n",
    "\n",
    "Vamos a implementar alguna modificación sobre el modelo inicial propuesto en la primera sesión.\n",
    "\n",
    "Para empezar vamos a definir un conjunto de validación. Con este conjunto de calidación extraído del propio conjunto de entrenamiento estimaremos los mejores parámetros. Dejaremos el conjunto de test sólo para estimar el acierto final con estos mejores parámetros.\n",
    "\n",
    "Primero leemos los datos y normalizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (60000, 28, 28)\n",
      "test set (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('test set', x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize [0..255]-->[0..1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición training/validación\n",
    "\n",
    "Nos quedaremos con un 80% de los datos para entrenar y un 20% para validar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (48000, 784)\n",
      "val set (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('val set', x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación con conjunto de validación\n",
    "\n",
    "Cualquier parámetro a modificar en nuestro modelo debería ser probado sobre el conjunto de validación y escoger aquel que produjera el mejor resultado para probar ese (y sólo ese) sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 7s 13ms/step - loss: 0.5391 - accuracy: 0.8531 - val_loss: 0.3106 - val_accuracy: 0.9143\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2807 - accuracy: 0.9206 - val_loss: 0.2497 - val_accuracy: 0.9314\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2304 - accuracy: 0.9353 - val_loss: 0.2145 - val_accuracy: 0.9417\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1987 - accuracy: 0.9448 - val_loss: 0.1913 - val_accuracy: 0.9470\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1766 - accuracy: 0.9500 - val_loss: 0.1751 - val_accuracy: 0.9516\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 13ms/step - loss: 0.5172 - accuracy: 0.8580 - val_loss: 0.3040 - val_accuracy: 0.9155\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2741 - accuracy: 0.9231 - val_loss: 0.2431 - val_accuracy: 0.9320\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2228 - accuracy: 0.9367 - val_loss: 0.2087 - val_accuracy: 0.9413\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.1895 - accuracy: 0.9472 - val_loss: 0.1834 - val_accuracy: 0.9488\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1654 - accuracy: 0.9537 - val_loss: 0.1658 - val_accuracy: 0.9538\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 9s 18ms/step - loss: 0.5014 - accuracy: 0.8649 - val_loss: 0.2968 - val_accuracy: 0.9159\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2653 - accuracy: 0.9254 - val_loss: 0.2407 - val_accuracy: 0.9333\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2156 - accuracy: 0.9401 - val_loss: 0.2011 - val_accuracy: 0.9452\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1830 - accuracy: 0.9493 - val_loss: 0.1759 - val_accuracy: 0.9511\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1579 - accuracy: 0.9562 - val_loss: 0.1615 - val_accuracy: 0.9545\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4962 - accuracy: 0.8654 - val_loss: 0.2946 - val_accuracy: 0.9204\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2589 - accuracy: 0.9282 - val_loss: 0.2338 - val_accuracy: 0.9344\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2090 - accuracy: 0.9420 - val_loss: 0.1955 - val_accuracy: 0.9444\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1759 - accuracy: 0.9511 - val_loss: 0.1713 - val_accuracy: 0.9516\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1515 - accuracy: 0.9586 - val_loss: 0.1537 - val_accuracy: 0.9567\n",
      "=============================\n",
      "Best acc 0.9567499756813049\n",
      "Best hidden dim 1024\n",
      "=============================\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.4455 - accuracy: 0.8819 - val_loss: 0.2595 - val_accuracy: 0.9287\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.2376 - accuracy: 0.9334 - val_loss: 0.1997 - val_accuracy: 0.9448\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1876 - accuracy: 0.9477 - val_loss: 0.1696 - val_accuracy: 0.9521\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1570 - accuracy: 0.9564 - val_loss: 0.1457 - val_accuracy: 0.9594\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1343 - accuracy: 0.9626 - val_loss: 0.1272 - val_accuracy: 0.9631\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "batch_size=128\n",
    "epochs=5  \n",
    "\n",
    "hdim=[128,256,512,1024]\n",
    "best_acc=0.0\n",
    "for h in hdim:\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(784))\n",
    "    model.add(Dense(h, activation='relu')) # <-- repetir esta línea tantas veces como número de capas ocultas se quiera\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val)) ## <--- OJO validation set\n",
    "    \n",
    "    if history.history['val_accuracy'][-1]>best_acc:\n",
    "        best_acc=history.history['val_accuracy'][-1]\n",
    "        besth=h\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"Best acc\",best_acc)\n",
    "print(\"Best hidden dim\",besth)\n",
    "print(\"=============================\")\n",
    "\n",
    "\n",
    "## PROBAR EL MEJOR CON TEST\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(besth, activation='relu'))  \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_combined = np.concatenate((x_train, x_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "history = model.fit(x_combined, y_combined, # <--- aquí podríamos concatenar trainin+valid para no malgastar datos\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sin train+val el resultado de acc es menor, 0.95+-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EARLY STOPPING\n",
    "\n",
    "De la multitud de parámetros a decidir en la definición y entrenamiento de las redes neuronales hay uno que podríamos automatizar. Es el número de epochs a emplear. Dado que tenemos un conjunto de validación vamos a emplearlo para monitorizar cómo evoluciona la convergencia. Si en algún momento el descenso por gradiente parece haber alcanzado una zona de meseta sobre dicho conjunto de validación podremos detener el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 12s 26ms/step - loss: 0.4944 - accuracy: 0.8653 - val_loss: 0.2986 - val_accuracy: 0.9173\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.2616 - accuracy: 0.9266 - val_loss: 0.2341 - val_accuracy: 0.9350\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2131 - accuracy: 0.9405 - val_loss: 0.1969 - val_accuracy: 0.9467\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.1796 - accuracy: 0.9502 - val_loss: 0.1745 - val_accuracy: 0.9520\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.1548 - accuracy: 0.9572 - val_loss: 0.1572 - val_accuracy: 0.9559\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.1361 - accuracy: 0.9624 - val_loss: 0.1443 - val_accuracy: 0.9597\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.1212 - accuracy: 0.9670 - val_loss: 0.1332 - val_accuracy: 0.9617\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1090 - accuracy: 0.9704 - val_loss: 0.1231 - val_accuracy: 0.9658\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0987 - accuracy: 0.9732 - val_loss: 0.1147 - val_accuracy: 0.9681\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0901 - accuracy: 0.9764 - val_loss: 0.1104 - val_accuracy: 0.9686\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0829 - accuracy: 0.9780 - val_loss: 0.1042 - val_accuracy: 0.9703\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0762 - accuracy: 0.9801 - val_loss: 0.0999 - val_accuracy: 0.9718\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0702 - accuracy: 0.9820 - val_loss: 0.0966 - val_accuracy: 0.9727\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0656 - accuracy: 0.9832 - val_loss: 0.0925 - val_accuracy: 0.9736\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0609 - accuracy: 0.9847 - val_loss: 0.0899 - val_accuracy: 0.9743\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0570 - accuracy: 0.9852 - val_loss: 0.0873 - val_accuracy: 0.9746\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0532 - accuracy: 0.9866 - val_loss: 0.0859 - val_accuracy: 0.9753\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0499 - accuracy: 0.9879 - val_loss: 0.0831 - val_accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) ## También podría ser 'loss' sin necesitar un conjunto de validación\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs=100  ## No nos preocupemos, el fit acabará antes por el early_stopping\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[callback])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ejercicio**:\n",
    "\n",
    "Entrenar una red neuronal MLP para el problema MNIST. Los valores que se quieren probar son los siguientes:\n",
    "\n",
    "-   Número de capas ocultas [1,2,3]\n",
    "-   Dimensión de las capas ocultas [512,1024]\n",
    "-   Learning rate [0.025, 0.01]\n",
    "-   Batch_size [128]\n",
    "-   Epochs con early_stopping\n",
    "\n",
    "Obtener la mejor combinación con el conjunto de validación y probarla finalmente sobre el conjunto de test.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 9s 20ms/step - loss: 0.3816 - accuracy: 0.8907 - val_loss: 0.2211 - val_accuracy: 0.9374\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1865 - accuracy: 0.9468 - val_loss: 0.1626 - val_accuracy: 0.9533\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1378 - accuracy: 0.9611 - val_loss: 0.1331 - val_accuracy: 0.9616\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1091 - accuracy: 0.9695 - val_loss: 0.1146 - val_accuracy: 0.9668\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0890 - accuracy: 0.9754 - val_loss: 0.1009 - val_accuracy: 0.9702\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0745 - accuracy: 0.9795 - val_loss: 0.0944 - val_accuracy: 0.9722\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0640 - accuracy: 0.9828 - val_loss: 0.0876 - val_accuracy: 0.9737\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0556 - accuracy: 0.9856 - val_loss: 0.0854 - val_accuracy: 0.9763\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0482 - accuracy: 0.9875 - val_loss: 0.0828 - val_accuracy: 0.9756\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0424 - accuracy: 0.9892 - val_loss: 0.0796 - val_accuracy: 0.9769\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.3756 - accuracy: 0.8944 - val_loss: 0.2267 - val_accuracy: 0.9359\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1844 - accuracy: 0.9482 - val_loss: 0.1591 - val_accuracy: 0.9549\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.1340 - accuracy: 0.9630 - val_loss: 0.1284 - val_accuracy: 0.9639\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.1043 - accuracy: 0.9720 - val_loss: 0.1117 - val_accuracy: 0.9667\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.0857 - accuracy: 0.9771 - val_loss: 0.1004 - val_accuracy: 0.9707\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0709 - accuracy: 0.9805 - val_loss: 0.0941 - val_accuracy: 0.9722\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0600 - accuracy: 0.9840 - val_loss: 0.0876 - val_accuracy: 0.9744\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.0518 - accuracy: 0.9860 - val_loss: 0.0819 - val_accuracy: 0.9763\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.0447 - accuracy: 0.9890 - val_loss: 0.0785 - val_accuracy: 0.9765\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0394 - accuracy: 0.9904 - val_loss: 0.0764 - val_accuracy: 0.9774\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0341 - accuracy: 0.9920 - val_loss: 0.0770 - val_accuracy: 0.9773\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0296 - accuracy: 0.9935 - val_loss: 0.0753 - val_accuracy: 0.9776\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.0263 - accuracy: 0.9947 - val_loss: 0.0721 - val_accuracy: 0.9782\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 9s 21ms/step - loss: 0.3645 - accuracy: 0.8933 - val_loss: 0.1698 - val_accuracy: 0.9505\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.1431 - accuracy: 0.9578 - val_loss: 0.1227 - val_accuracy: 0.9630\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.0945 - accuracy: 0.9718 - val_loss: 0.0984 - val_accuracy: 0.9708\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.0714 - accuracy: 0.9789 - val_loss: 0.0910 - val_accuracy: 0.9722\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 0.0785 - val_accuracy: 0.9762\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.0414 - accuracy: 0.9880 - val_loss: 0.0710 - val_accuracy: 0.9784\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.0686 - val_accuracy: 0.9795\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0249 - accuracy: 0.9934 - val_loss: 0.0680 - val_accuracy: 0.9789\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.0194 - accuracy: 0.9954 - val_loss: 0.0687 - val_accuracy: 0.9796\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.0703 - val_accuracy: 0.9791\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.0690 - val_accuracy: 0.9796\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 24s 60ms/step - loss: 0.3460 - accuracy: 0.9003 - val_loss: 0.1781 - val_accuracy: 0.9493\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.1338 - accuracy: 0.9612 - val_loss: 0.1295 - val_accuracy: 0.9597\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.0882 - accuracy: 0.9739 - val_loss: 0.1011 - val_accuracy: 0.9703\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 0.0630 - accuracy: 0.9818 - val_loss: 0.1066 - val_accuracy: 0.9677\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 0.0487 - accuracy: 0.9857 - val_loss: 0.0795 - val_accuracy: 0.9742\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.0721 - val_accuracy: 0.9774\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0701 - val_accuracy: 0.9794\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 0.0200 - accuracy: 0.9954 - val_loss: 0.0677 - val_accuracy: 0.9811\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.0652 - val_accuracy: 0.9799\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 17s 44ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.0720 - val_accuracy: 0.9798\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0731 - val_accuracy: 0.9792\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 13s 31ms/step - loss: 0.3624 - accuracy: 0.8919 - val_loss: 0.1590 - val_accuracy: 0.9507\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 10s 28ms/step - loss: 0.1225 - accuracy: 0.9634 - val_loss: 0.1181 - val_accuracy: 0.9635\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 10s 27ms/step - loss: 0.0812 - accuracy: 0.9752 - val_loss: 0.0891 - val_accuracy: 0.9726\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 11s 28ms/step - loss: 0.0563 - accuracy: 0.9830 - val_loss: 0.0799 - val_accuracy: 0.9753\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0403 - accuracy: 0.9880 - val_loss: 0.0812 - val_accuracy: 0.9756\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 11s 28ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0750 - val_accuracy: 0.9784\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.0223 - accuracy: 0.9935 - val_loss: 0.0789 - val_accuracy: 0.9772\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 10s 27ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0747 - val_accuracy: 0.9804\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 10s 25ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.0801 - val_accuracy: 0.9796\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 26s 67ms/step - loss: 0.3439 - accuracy: 0.9005 - val_loss: 0.1526 - val_accuracy: 0.9537\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 0.1177 - accuracy: 0.9650 - val_loss: 0.1122 - val_accuracy: 0.9651\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.0729 - accuracy: 0.9785 - val_loss: 0.0865 - val_accuracy: 0.9731\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.0814 - val_accuracy: 0.9752\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 25s 67ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0753 - val_accuracy: 0.9780\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 28s 76ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0727 - val_accuracy: 0.9789\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.0745 - val_accuracy: 0.9780\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 30s 79ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.0797 - val_accuracy: 0.9787\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 9s 20ms/step - loss: 0.5109 - accuracy: 0.8601 - val_loss: 0.2978 - val_accuracy: 0.9172\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2681 - accuracy: 0.9244 - val_loss: 0.2402 - val_accuracy: 0.9320\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2159 - accuracy: 0.9396 - val_loss: 0.2024 - val_accuracy: 0.9436\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.1813 - accuracy: 0.9493 - val_loss: 0.1780 - val_accuracy: 0.9503\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.1574 - accuracy: 0.9565 - val_loss: 0.1595 - val_accuracy: 0.9553\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.1379 - accuracy: 0.9616 - val_loss: 0.1455 - val_accuracy: 0.9587\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.1230 - accuracy: 0.9661 - val_loss: 0.1330 - val_accuracy: 0.9612\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.1109 - accuracy: 0.9697 - val_loss: 0.1261 - val_accuracy: 0.9632\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.1009 - accuracy: 0.9728 - val_loss: 0.1166 - val_accuracy: 0.9664\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0918 - accuracy: 0.9752 - val_loss: 0.1132 - val_accuracy: 0.9681\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0847 - accuracy: 0.9776 - val_loss: 0.1069 - val_accuracy: 0.9704\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0782 - accuracy: 0.9792 - val_loss: 0.1034 - val_accuracy: 0.9707\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0726 - accuracy: 0.9809 - val_loss: 0.0990 - val_accuracy: 0.9716\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0675 - accuracy: 0.9831 - val_loss: 0.0966 - val_accuracy: 0.9718\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0632 - accuracy: 0.9838 - val_loss: 0.0944 - val_accuracy: 0.9728\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 13s 32ms/step - loss: 0.4949 - accuracy: 0.8668 - val_loss: 0.2893 - val_accuracy: 0.9212\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 10s 28ms/step - loss: 0.2617 - accuracy: 0.9254 - val_loss: 0.2340 - val_accuracy: 0.9355\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 10s 28ms/step - loss: 0.2117 - accuracy: 0.9416 - val_loss: 0.2017 - val_accuracy: 0.9459\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1786 - accuracy: 0.9504 - val_loss: 0.1726 - val_accuracy: 0.9533\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.1548 - accuracy: 0.9577 - val_loss: 0.1558 - val_accuracy: 0.9571\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1357 - accuracy: 0.9631 - val_loss: 0.1451 - val_accuracy: 0.9603\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 10s 27ms/step - loss: 0.1204 - accuracy: 0.9672 - val_loss: 0.1318 - val_accuracy: 0.9643\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 10s 27ms/step - loss: 0.1083 - accuracy: 0.9709 - val_loss: 0.1227 - val_accuracy: 0.9661\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0986 - accuracy: 0.9736 - val_loss: 0.1151 - val_accuracy: 0.9682\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 11s 28ms/step - loss: 0.0895 - accuracy: 0.9766 - val_loss: 0.1107 - val_accuracy: 0.9680\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.0824 - accuracy: 0.9780 - val_loss: 0.1050 - val_accuracy: 0.9701\n",
      "Epoch 12/100\n",
      "162/375 [===========>..................] - ETA: 4s - loss: 0.0766 - accuracy: 0.9802"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mh:\\Documentos\\.UPV\\4t\\APR\\Practicas\\P2\\p2.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             optimizer\u001b[39m=\u001b[39msgd,\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m             metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m  \u001b[39m## No nos preocupemos, el fit acabará antes por el early_stopping\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(x_val, y_val),\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[callback])  \n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m>\u001b[39mbest_acc:\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Documentos/.UPV/4t/APR/Practicas/P2/p2.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     best_acc\u001b[39m=\u001b[39mhistory\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_capas_ocultas = [1,2,3]\n",
    "dim_capas_ocultas = [512, 1024]\n",
    "learningRate = [0.025, 0.01]\n",
    "batch_size = 128\n",
    "param = []\n",
    "for lr in learningRate:\n",
    "    for n in num_capas_ocultas:\n",
    "        for d in dim_capas_ocultas:\n",
    "            model = Sequential()\n",
    "            model.add(Input(784))\n",
    "            for numCapas in range(n):\n",
    "                model.add(Dense(d, activation='relu'))\n",
    "            model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "            sgd=SGD(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "            callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) ## También podría ser 'loss' sin necesitar un conjunto de validación\n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=sgd,\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "            epochs=100  ## No nos preocupemos, el fit acabará antes por el early_stopping\n",
    "            history = model.fit(x_train, y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                verbose=1,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                callbacks=[callback])  \n",
    "            if history.history['val_accuracy'][-1]>best_acc:\n",
    "                best_acc=history.history['val_accuracy'][-1]\n",
    "                besth=h\n",
    "                param = \"Learning rate: \" + str(lr) +\" \\n Numero de capas ocultas: \" + str(n) + \"Dimension capas ocultas: \" +str(d)\n",
    "\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"Best acc\",best_acc)\n",
    "print(\"Best hidden dim\",besth)\n",
    "print(\"..............Best param........ \\n\" , param)\n",
    "print(\"=============================\")\n",
    "\n",
    "## PROBAR EL MEJOR CON TEST\n",
    "model = Sequential()\n",
    "model.add(Input(784))\n",
    "model.add(Dense(besth, activation='relu'))  \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) ## También podría ser 'loss' sin necesitar un conjunto de validación\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "x_combined = np.concatenate((x_train, x_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "history = model.fit(x_combined, y_combined, # <--- aquí podríamos concatenar trainin+valid para no malgastar datos\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[callback]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model checkpoint\n",
    "\n",
    "Los model checkpoint permiten almacenar el estado del modelo en un punto intermedio del entrenamiento. Esto es útil para poder recuperar el modelo en caso de que el entrenamiento se interrumpa por cualquier motivo. Así como para poder recuperar el mejor modelo obtenido durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.4950 - accuracy: 0.8666\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91442, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4922 - accuracy: 0.8673 - val_loss: 0.2980 - val_accuracy: 0.9144\n",
      "Epoch 2/100\n",
      " 14/375 [>.............................] - ETA: 3s - loss: 0.2746 - accuracy: 0.9269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\envs\\vsc\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.9265\n",
      "Epoch 2: val_accuracy improved from 0.91442 to 0.93392, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2613 - accuracy: 0.9265 - val_loss: 0.2340 - val_accuracy: 0.9339\n",
      "Epoch 3/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.2114 - accuracy: 0.9412\n",
      "Epoch 3: val_accuracy improved from 0.93392 to 0.94600, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2113 - accuracy: 0.9412 - val_loss: 0.1972 - val_accuracy: 0.9460\n",
      "Epoch 4/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.1781 - accuracy: 0.9507\n",
      "Epoch 4: val_accuracy improved from 0.94600 to 0.95225, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1782 - accuracy: 0.9505 - val_loss: 0.1741 - val_accuracy: 0.9523\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9572\n",
      "Epoch 5: val_accuracy improved from 0.95225 to 0.95792, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1541 - accuracy: 0.9572 - val_loss: 0.1554 - val_accuracy: 0.9579\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9629\n",
      "Epoch 6: val_accuracy improved from 0.95792 to 0.96108, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1355 - accuracy: 0.9629 - val_loss: 0.1414 - val_accuracy: 0.9611\n",
      "Epoch 7/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.9671\n",
      "Epoch 7: val_accuracy improved from 0.96108 to 0.96367, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1208 - accuracy: 0.9672 - val_loss: 0.1315 - val_accuracy: 0.9637\n",
      "Epoch 8/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.9707\n",
      "Epoch 8: val_accuracy improved from 0.96367 to 0.96558, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1086 - accuracy: 0.9707 - val_loss: 0.1218 - val_accuracy: 0.9656\n",
      "Epoch 9/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9738\n",
      "Epoch 9: val_accuracy improved from 0.96558 to 0.96825, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0986 - accuracy: 0.9737 - val_loss: 0.1140 - val_accuracy: 0.9682\n",
      "Epoch 10/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9763\n",
      "Epoch 10: val_accuracy improved from 0.96825 to 0.96842, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0899 - accuracy: 0.9763 - val_loss: 0.1102 - val_accuracy: 0.9684\n",
      "Epoch 11/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9784\n",
      "Epoch 11: val_accuracy improved from 0.96842 to 0.96983, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0825 - accuracy: 0.9784 - val_loss: 0.1054 - val_accuracy: 0.9698\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9804\n",
      "Epoch 12: val_accuracy improved from 0.96983 to 0.97092, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0760 - accuracy: 0.9804 - val_loss: 0.1014 - val_accuracy: 0.9709\n",
      "Epoch 13/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0704 - accuracy: 0.9818\n",
      "Epoch 13: val_accuracy improved from 0.97092 to 0.97283, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0705 - accuracy: 0.9818 - val_loss: 0.0992 - val_accuracy: 0.9728\n",
      "Epoch 14/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0654 - accuracy: 0.9838\n",
      "Epoch 14: val_accuracy improved from 0.97283 to 0.97350, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0654 - accuracy: 0.9837 - val_loss: 0.0939 - val_accuracy: 0.9735\n",
      "Epoch 15/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9845\n",
      "Epoch 15: val_accuracy improved from 0.97350 to 0.97392, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0608 - accuracy: 0.9845 - val_loss: 0.0897 - val_accuracy: 0.9739\n",
      "Epoch 16/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9862\n",
      "Epoch 16: val_accuracy improved from 0.97392 to 0.97508, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0569 - accuracy: 0.9862 - val_loss: 0.0870 - val_accuracy: 0.9751\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9869\n",
      "Epoch 17: val_accuracy improved from 0.97508 to 0.97517, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0532 - accuracy: 0.9869 - val_loss: 0.0857 - val_accuracy: 0.9752\n",
      "Epoch 18/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9879\n",
      "Epoch 18: val_accuracy improved from 0.97517 to 0.97600, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0498 - accuracy: 0.9880 - val_loss: 0.0835 - val_accuracy: 0.9760\n",
      "Epoch 19/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9890\n",
      "Epoch 19: val_accuracy did not improve from 0.97600\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0471 - accuracy: 0.9890 - val_loss: 0.0814 - val_accuracy: 0.9758\n",
      "Test loss: 0.07736046612262726\n",
      "Test accuracy: 0.9768999814987183\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "epochs=100 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu')) \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) \n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[callback, checkpoint]) ## <--- dos callbacks, el early_stopping y el model_checkpoint\n",
    "\n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar parámetros\n",
    "\n",
    "Es posible que en el ejemplo anterior el entrenamiento haya acabado prematuramente por el efecto del Early Stopping. En ese caso, el modelo que se ha obtenido no es el mejor posible. Para obtener el mejor modelo quizás sea necesario aumentar el número de epochs y para ello modificar algún parámetro del early stopping.\n",
    "\n",
    "## Ejercicio: \n",
    "\n",
    "Modificar el early stopping y emplear un modelo con los mejores parámetros (número de capas ocultas, learning rate, batch size, etc) para evaluar finalmente el modelo guardado sobre el test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=100 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu')) \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) \n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[callback, checkpoint]) ## <--- dos callbacks, el early_stopping y el model_checkpoint\n",
    "\n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
